---
title: ADR-002 ML-модель для персонализированной классификации трат
sidebar_label: ADR-002
---

**Status:** Accepted

**Date:** 2025-11-01

**Version:** 2.0

---

## **Business Goal**

**Цель проекта:** Разработать систему автоматической классификации финансовых трат пользователей по персонализированным категориям с возможностью обучения на основе обратной связи.

**Проблема:** Пользователи ведут учет финансов, загружая чеки и транзакции. Ручная категоризация занимает много времени. Каждый пользователь использует свои категории (например, один может использовать "Продукты" и "Кафе", другой — "Еда дома" и "Рестораны"), что делает невозможным использование единой глобальной модели классификации.

**Решение:** Персонализированные ML-модели для каждого пользователя, обучаемые на его исторических данных с возможностью улучшения через обратную связь.

---

## **ML Task Definition**

### Задача машинного обучения

**Тип задачи:** Многоклассовая классификация текста с персонализацией

**Входные данные:**
- Текстовое описание транзакции (например: "Покупка в магазине Пятёрочка, хлеб, молоко")
- История транзакций пользователя с категориями
- Персональный набор категорий пользователя

**Выходные данные:**
- Предсказанная категория транзакции (из набора категорий пользователя)
- Уверенность модели в предсказании (probability score)

**Особенности задачи:**

1. **Персонализация:** Каждый пользователь имеет свой уникальный набор категорий

2. **Динамичность:** Пользователь может добавлять/удалять категории, изменять классификацию

3. **Несбалансированность:** Некоторые категории могут иметь значительно больше примеров, чем другие

4. **Холодный старт:** Новые пользователи и новые категории требуют быстрой адаптации модели

---

## **Target Metrics**

### Оффлайн метрики (Offline Evaluation)

Оффлайн метрики используются для оценки качества модели на исторических данных и датасетах до развертывания в продакшн.

#### Метрики классификации (на уровне пользователя)

| Метрика | Целевое значение | Описание |
|---------|------------------|----------|
| **Accuracy** | ≥ 85% | Доля корректно классифицированных транзакций |
| **Macro F1-score** | ≥ 0.80 | Среднее F1-score по всем категориям (учитывает несбалансированность) |
| **Weighted F1-score** | ≥ 0.85 | F1-score, взвешенный по частоте категорий |
| **Top-3 Accuracy** | ≥ 95% | Доля случаев, когда правильная категория в топ-3 предсказаний |
| **Per-category Precision** | ≥ 0.75 (min) | Минимальная точность для каждой категории |

#### Метрики для малых данных (Few-shot learning)

| Метрика | Целевое значение | Описание |
|---------|------------------|----------|
| **Accuracy @ 5 examples** | ≥ 60% | Точность после 5 примеров новой категории |
| **Accuracy @ 10 examples** | ≥ 75% | Точность после 10 примеров новой категории |
| **Accuracy @ 20 examples** | ≥ 85% | Точность после 20 примеров новой категории |

#### Метрики на публичных датасетах

Для валидации подхода на публичных датасетах (оффлайн):

- **Technology Product Categorization** — точность классификации продуктов по описанию
- **Massive Product Text Classification Dataset** (Kaggle) — метрики на датасете названий товаров с категориями Amazon
- **PriceRunner Dataset** — точность на 35K предложениях из 10 категорий
- **AlleNoise** — метрики на 500K+ текстах из 5 692 категорий (масштабируемость)

**Целевые метрики на публичных датасетах:**
- Accuracy: ≥ 80% (для сравнения с baseline)
- Macro F1: ≥ 0.75

### Онлайн метрики (Online Evaluation)

Онлайн метрики отслеживаются в реальном времени на продакшн данных.

#### Метрики качества предсказаний

| Метрика | Целевое значение | Описание |
|---------|------------------|----------|
| **User Acceptance Rate** | ≥ 90% | Доля предсказаний, принятых пользователем без исправления |
| **Correction Rate** | ≤ 10% | Доля транзакций, где пользователь изменил категорию |
| **Accuracy (user feedback)** | ≥ 90% | Точность на основе подтвержденных пользователем категорий |
| **Average Confidence** | ≥ 0.80 | Средняя уверенность модели в правильных предсказаниях |

#### Метрики обучения и адаптации

| Метрика | Целевое значение | Описание |
|---------|------------------|----------|
| **Time to First Prediction** | ≤ 5 секунд | Время от создания аккаунта до первого предсказания |
| **Learning Speed** | ≤ 10 примеров | Количество примеров для достижения 80% accuracy |
| **Model Update Frequency** | ≤ 24 часа | Максимальный интервал между обновлениями модели |

#### Метрики производительности

| Метрика | Целевое значение | Описание |
|---------|------------------|----------|
| **P50 Latency** | ≤ 200 мс | Медианное время ответа API предсказания |
| **P95 Latency** | ≤ 500 мс | 95-й перцентиль времени ответа |
| **P99 Latency** | ≤ 1000 мс | 99-й перцентиль времени ответа |
| **Error Rate** | ≤ 1% | Доля запросов с ошибками (5xx, таймауты) |
| **Model Training Time** | ≤ 30 сек | Время полного переобучения персональной модели |
| **Memory Usage** | ≤ 2 GB на 1000 пользователей | Объем памяти для моделей и данных |

---

## **Data Sources**

### Источники данных для обучения

#### 1. Операции с категориями (Auto-confirmed data)

**Описание:** Если у транзакции уже есть категория, проставленная пользователем (вручную или из предыдущего предсказания, которое пользователь не исправил), считаем это правильной меткой.

**Источник данных:**
- Таблица `transactions` с полем `category_id IS NOT NULL`
- Исключаем транзакции, где `category_id != predicted_category_id` (они попадают в feedback)

**Критерии качества:**
- Используем только транзакции, где `category_id` был установлен пользователем (не автоматически)
- Исключаем транзакции с `predicted_category_id` которые были изменены пользователем

**Объем данных:** Основной источник данных для обучения (≈80-90% обучающей выборки)

#### 2. Фидбек от пользователей (User feedback data)

**Описание:** Когда модель предсказала одну категорию, а пользователь вручную изменил её на другую — это явный сигнал о неправильном предсказании.

**Источник данных:**
- Таблица `feedback_events` с типом `correction`
- Поля: `predicted_category_id`, `correct_category_id`, `prediction_confidence`

**Критерии качества:**
- Используем событие как негативный пример для `predicted_category_id` и позитивный для `correct_category_id`
- Или используем только позитивный пример (предпочтительно для избежания дисбаланса)

**Объем данных:** Важный источник для коррекции модели (≈10-20% обучающей выборки)

#### 3. Публичные датасеты (Offline evaluation)

**Описание:** Используются только для оффлайн оценки и валидации подходов, не для обучения персональных моделей.

**Доступные датасеты:**

**Technology Product Categorization**

   - Описания программных продуктов с категориями

   - Подходит для валидации подхода к классификации по тексту


**Massive Product Text Classification Dataset** (Kaggle)

   - Датасет: [Massive Product Text Classification Dataset](https://www.kaggle.com/datasets/asaniczka/product-titles-text-classification/data)

   - Названия товаров с категориями для задач классификации текста

   - Подходит для валидации подхода к классификации коротких текстовых описаний

   - Используется для оффлайн оценки качества модели на релевантных данных (аналогично описаниям транзакций)

**PriceRunner Dataset**

   - 35 311 предложений из 10 категорий

   - Текстовые описания товаров с категориями

**AlleNoise**

   - 500 000+ коротких текстов (названия товаров) из 5 692 категорий

   - Бенчмарк для оценки масштабируемости

**Spending Habits by Category and Item** (Kaggle)

   - Синтетические данные о привычках трат

   - Для анализа паттернов потребительского поведения

**Student Spending Habits Dataset** (Kaggle)

   - Синтетические данные о тратах 1000 студентов

   - Демографические и академические характеристики

### Стратегия использования данных

#### Для обучения персональных моделей:

- **Основной источник:** Операции с категориями (auto-confirmed)

- **Корректирующий источник:** Фидбек от пользователей (user feedback)

- **Исключаем:** Публичные датасеты (не релевантны для персональных категорий)

#### Для оффлайн оценки:

- **Публичные датасеты:** Для валидации общего подхода и сравнения с baseline

- **Сплит данных пользователя:** Train/Validation/Test (80/10/10) для оценки персональных моделей

---

## **Context**

В рамках общей архитектуры системы ([ADR-001](001-global-adr.md)) необходимо определить подход к машинному обучению для персонализированной классификации транзакций.

**Архитектурный контекст:**
- Общий эмбеддер для текстовых описаний (sentence-transformers)
- Персональный классификатор для каждого пользователя
- База данных с транзакциями, категориями и фидбеком

**Workflow обучения:**

1. **Сбор данных:** Система собирает данные из операций и фидбека пользователя
2. **Предобработка:** Текстовые описания → эмбеддинги через общий эмбеддер
3. **Обучение:** Персональный классификатор обучается на парах (embedding, category)
4. **Валидация:** Оценка качества на validation set
5. **Развертывание:** Сохранение модели и использование для предсказаний

**Workflow предсказания:**

1. **Запрос:** Пользователь создает транзакцию с описанием
2. **Эмбеддинг:** Описание → вектор через общий эмбеддер
3. **Классификация:** Вектор → категория через персональный классификатор
4. **Обратная связь:** Пользователь может скорректировать категорию
5. **Дообучение:** Периодическое переобучение на основе новых данных

---

## **Decision**

### Основная идея

Использовать **общую модель эмбеддингов** для текстовых описаний транзакций
и **персональные классификаторы** для каждого пользователя.

### ⚙️ Компоненты

| Компонент                   | Описание                                                                                                                                             |
| --------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Embedding Service**       | Общая LLM-модель (например, `sentence-transformers/all-MiniLM-L6-v2`), преобразующая текст описания траты в вектор фиксированной длины. Эмбеддер общий для всех пользователей, не требует дообучения. |
| **User Classifier Service** | Лёгкий классификатор (например, `sklearn.LogisticRegression` или `MLP`), обучаемый на данных конкретного пользователя: пары `(embedding, category)`. Одна модель на пользователя. |
| **Training Data Collector** | Сбор обучающих данных из двух источников: (1) транзакции с подтвержденными категориями, (2) фидбек от пользователей (корректировки категорий). |
| **Feedback Loop**           | При изменении пользователем категории, событие записывается в обучающий датасет. Периодически (например, при накоплении N новых примеров или раз в день) инициируется дообучение персональной модели. |
| **Metrics Tracker**         | Система отслеживания оффлайн и онлайн метрик: логирование предсказаний, фидбека, времени отклика, качества модели. |
| **Storage**                 | Хранилище для пользовательских категорий, транзакций и параметров моделей. На этапе MVP — SQLite или JSON. В продакшене — PostgreSQL + S3 для моделей. |
| **API Layer (FastAPI)**     | REST-интерфейс: `/upload` (загрузка чеков), `/predict` (предсказание категории), `/feedback` (корректировка категории), `/train` (запуск обучения). |

### Data Flow

```
1. Пользователь загружает чек: POST /upload
   └─> Текст описания сохраняется в Storage

2. Пользователь запрашивает классификацию: POST /predict
   ├─> Embedding Service: текст → вектор (384 dim)
   ├─> User Classifier Service: вектор → категория + вероятность
   ├─> Сохранение предсказания в transactions (predicted_category_id)
   └─> Возврат предсказания пользователю

3. Пользователь подтверждает или исправляет категорию: POST /feedback
   ├─> Если категория подтверждена: используется как auto-confirmed training data
   ├─> Если категория изменена: создается feedback_event
   └─> Сохранение пары (embedding, правильная категория) в training_data

4. Периодическое дообучение (автоматически или по запросу): POST /train
   ├─> Training Data Collector: сбор данных из transactions и feedback_events
   ├─> Предобработка: фильтрация и валидация данных
   ├─> Сплит на Train/Validation (80/20)
   ├─> Обучение/переобучение User Classifier
   ├─> Оценка метрик на validation set
   ├─> Сохранение обновленной модели в Storage
   └─> Обновление метрик в user_classifier_models
```

---

## **Evaluation Strategy**

### Оффлайн оценка (Offline Evaluation)

#### 1. Валидация на публичных датасетах

**Цель:** Проверить общий подход к классификации текста на релевантных датасетах.

**Процесс:**

1. Загрузка публичных датасетов (Product Titles Text Classification, Technology Product Categorization, PriceRunner, AlleNoise, etc.)
2. Преобразование категорий в формат задачи (многоклассовая классификация)
3. Обучение общего классификатора (без персонализации) на эмбеддингах
4. Оценка метрик: Accuracy, Macro F1, Weighted F1
5. Сравнение с baseline моделями (например, TF-IDF + LogisticRegression)

**Ожидаемые результаты:**

- Accuracy ≥ 80%
- Macro F1 ≥ 0.75
- Подтверждение эффективности подхода с эмбеддингами

#### 2. Валидация персональных моделей

**Цель:** Оценить качество персональных моделей на исторических данных пользователей.

**Процесс:**

1. Для каждого пользователя с достаточным количеством данных (≥100 транзакций):
   - Сплит данных: Train (80%) / Validation (10%) / Test (10%)
   - Временной сплит: старые данные → train, новые → test (для реалистичности)
2. Обучение модели на train set
3. Оценка на validation и test sets
4. Агрегация метрик по всем пользователям

**Метрики:**

- Accuracy, Macro F1, Weighted F1
- Per-category metrics (precision, recall)
- Top-3 Accuracy

#### 3. Few-shot learning evaluation

**Цель:** Проверить способность модели быстро адаптироваться к новым категориям.

**Процесс:**

1. Выбор категорий с достаточным количеством примеров (≥50)
2. Симуляция few-shot сценария:
   - Использовать 5, 10, 20 примеров для обучения
   - Остальные примеры для тестирования
3. Оценка Accuracy @ 5/10/20 examples

### Онлайн оценка (Online Evaluation)

#### 1. Метрики в реальном времени

**User Acceptance Rate:**
```
UAR = (количество транзакций без изменения категории) / (общее количество транзакций)
```

**Correction Rate:**
```
CR = (количество транзакций с изменением категории) / (общее количество транзакций)
```

**Accuracy (user feedback):**
```
Accuracy = (количество правильных предсказаний) / (количество транзакций с категорией)
где правильное предсказание = predicted_category_id == category_id
```

#### 2. A/B тестирование

**Цель:** Сравнить разные подходы или гиперпараметры.

**Стратегия:**

- Разделение пользователей на группы (A/B)
- Разные модели или параметры для каждой группы
- Сравнение онлайн метрик между группами
- Статистическая значимость различий

#### 3. Мониторинг качества

**Метрики для отслеживания:**

- User Acceptance Rate (должен быть стабильным или расти)
- Correction Rate (должен снижаться со временем)
- Average Confidence (должен быть высоким для принятых предсказаний)
- Distribution of corrections (какие категории чаще исправляются)

### Стратегия оценки для новых пользователей

**Cold Start Problem:**

- Новые пользователи без истории транзакций
- Новые категории без примеров

**Подход:**

1. **Fallback механизм:** Использование правил или zero-shot классификации
2. **Быстрое обучение:** При первых 5-10 примерах — обучение простой модели (LogisticRegression)
3. **Метрики:** Отслеживание Learning Speed (сколько примеров нужно для 80% accuracy)

---

## **Technology Stack**

### Core ML Libraries
- **`sentence-transformers`**: Для генерации эмбеддингов (модель `all-MiniLM-L6-v2` или аналогичная)
- **`scikit-learn`**: Для персональных классификаторов (LogisticRegression, MLPClassifier)
- **`transformers` / `huggingface-hub`**: Для сохранения моделей в формате Hugging Face

### Backend & API
- **`fastapi`**: REST API для загрузки данных, предсказаний и обратной связи
- **`uvicorn`**: ASGI-сервер для запуска FastAPI
- **`pydantic`**: Валидация входных данных и конфигураций

### Data Storage (MVP)
- **`sqlite3`**: Локальное хранилище транзакций и метаданных
- **`joblib` / `pickle`**: Сохранение обученных классификаторов

### Data Processing
- **`pandas`**: Обработка и предобработка данных
- **`numpy`**: Работа с массивами и векторами

### Configuration & Logging
- **`pyyaml`** или **`toml`**: Конфигурационные файлы для обучения
- **`logging`**: Логирование процесса обучения и работы API

### Testing & Quality
- **`pytest`**: Тестирование
- **`black`**: Форматирование кода
- **`ruff`**: Линтинг
- **`mypy`**: Проверка типов (опционально)

---

## **Rationale**

- **Персонализация** — каждая модель отражает индивидуальные привычки пользователя

- **Масштабируемость** — общий эмбеддер позволяет обслуживать тысячи пользователей

- **Низкие издержки** — дообучение выполняется локально, без необходимости retrain большой LLM

- **Интерпретируемость** — можно легко отладить и объяснить предсказания (через ближайшие эмбеддинги)

- **Быстрый отклик** — классификация = вызов эмбеддера + линейная модель

---

## **Alternatives Considered**

| Вариант                                        | Почему отклонён                                                                       |
| ---------------------------------------------- | ------------------------------------------------------------------------------------- |
| **Одна глобальная классификационная модель**   | Невозможно учесть индивидуальные категории; необходимо централизованное переобучение. |
| **Fine-tuning LLM на всех данных**             | Непрактично из-за ресурсоёмкости и частых обновлений пользовательских категорий.      |
| **Zero-shot классификация (LLM без обучения)** | Может работать как fallback, но даёт низкую точность при пользовательских категориях. |

---

## **Consequences**

**Плюсы:**

* Простая реализация и развёртывание;
* Легко масштабируется (общий эмбеддер + легкие персональные классификаторы);
* Удобно тестировать и воспроизводить;
* Быстрая инференс-стадия (эмбеддинг + линейная модель);
* Персонализация без компромиссов (каждый пользователь — своя модель);
* Низкие вычислительные затраты на дообучение (обучаем только легкий классификатор).

**Минусы:**

* Нужно хранить множество маленьких моделей (один классификатор на пользователя);
* Переобучение может занимать время при большом количестве пользователей (нужна очередь задач);
* Зависимость от эмбеддинговой модели (нужно контролировать версии и совместимость);
* Холодный старт: новые пользователи без истории нуждаются в первоначальной разметке (или fallback на zero-shot).

**Риски и митигация:**

* **Риск:** Низкая точность для новых пользователей
  **Митигация:** Fallback на правила или zero-shot классификацию до накопления достаточного количества примеров (≥10)
* **Риск:** Переобучение модели при малом датасете
  **Митигация:** Регуляризация, early stopping, кросс-валидация
* **Риск:** Масштабирование при росте числа пользователей
  **Митигация:** Асинхронная очередь обучения, батчинг запросов к эмбеддеру

---

## **Future Improvements**

1. **Active Learning:** при низкой уверенности запрашивать подтверждение у пользователя.
2. **Federated Learning:** агрегировать пользовательские модели для общей инициализации.
3. **Streaming retraining:** обновлять классификатор инкрементально, без полного переобучения.
4. **Vector DB:** хранить эмбеддинги в Qdrant / FAISS / Milvus для быстрого поиска похожих транзакций.
